{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f9b3697-fd4c-435f-8518-b930b17b40d5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Projet 5 - Segmentez des clients d'un site e-commerce - Durée de vie du clustering\n",
    ">-\n",
    "# 1. Initialisation, visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6874ca12-0fc4-431d-b94f-41f99c1afc42",
   "metadata": {
    "tags": []
   },
   "source": [
    ">>-\n",
    "## 11. Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df3bbaa-d810-4b18-a0dd-e504b62336cb",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    ">>>-\n",
    "### 111. Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1449b0-98bf-4224-bcd1-6bdbb7caae6e",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np              # fast thus always used\n",
    "import pandas as pd             # fast\n",
    "pd.set_option(\"display.max_rows\", 20, \"display.max_columns\", None)\n",
    "import matplotlib.pyplot as plt # slow: 233 ns\n",
    "import seaborn as sns           # SLOW BUT: 80.4 ns\n",
    "sns.set_style(\"whitegrid\")      # \"ticks\", \"white\"\n",
    "import re\n",
    "import my\n",
    "import datetime\n",
    "from scipy import interpolate   # FAST BUT: 319 ns ± 2.64 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n",
    "#  %timeit import geopandas     # SLOW \n",
    "import timeit\n",
    "#import os\n",
    "#import sys\n",
    "from IPython.display import clear_output\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "289bea9a-0794-409d-b826-ee37cbada2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479cee51-bba7-41b1-82ca-8b6b71bcdb08",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    ">>>-\n",
    "### 112. Data imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50be1af8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dfs1 = pd.read_csv(\"olist_customers_dataset.csv\") #, sep=\"\\t\")\n",
    "dfs2 = pd.read_csv(\"olist_geolocation_dataset.csv\") #, sep=\"\\t\")\n",
    "dfs3 = pd.read_csv(\"olist_order_items_dataset.csv\") #, sep=\"\\t\")\n",
    "dfs4 = pd.read_csv(\"olist_order_payments_dataset.csv\") #, sep=\"\\t\")\n",
    "dfs5 = pd.read_csv(\"olist_order_reviews_dataset.csv\") #, sep=\"\\t\")\n",
    "dfs6 = pd.read_csv(\"olist_orders_dataset.csv\") #, sep=\"\\t\")\n",
    "dfs7 = pd.read_csv(\"olist_products_dataset.csv\") #, sep=\"\\t\")\n",
    "dfs8 = pd.read_csv(\"olist_sellers_dataset.csv\") #, sep=\"\\t\")\n",
    "dfs9 = pd.read_csv('product_category_name_translation.csv') #, sep='\\t')\n",
    "dfs = [dfs1, dfs2, dfs3, dfs4, dfs5, dfs6, dfs7, dfs8, dfs9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe37a686-7032-4e02-8645-5be8aeb8e269",
   "metadata": {},
   "source": [
    "Je ne suis pas très content de cette solution pour pouvoir itérer sur les 9 df car je crée un objet dfs gigantesque, alors que je veux juste une liste qui renvoie vers chacun des 9 df sans contenir leur contenu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed16fa24-4326-4c8c-9932-ecd3aaadb43a",
   "metadata": {},
   "source": [
    ">-\n",
    "# 4. Fabrication des dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0255e0-d3cb-4dec-b0d2-d582a4817e78",
   "metadata": {},
   "source": [
    ">>-\n",
    "## 41. Merge_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84963e37-79e7-40f6-9ecc-5a3b941a241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs1[[\"customer_id\",\"customer_unique_id\"]].merge(dfs6[[\"customer_id\",\"order_id\",\"order_purchase_timestamp\"]], on=\"customer_id\", how=\"outer\")\n",
    "df = df.merge(dfs4[[\"order_id\",\"payment_value\"]], on=\"order_id\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d6ef6a-a7a5-4590-8900-75a6da47f0b2",
   "metadata": {},
   "source": [
    ">>-\n",
    "## 42. Cleaning_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb5f5625-644a-4c5b-a8c0-2965ce65adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_elt = list(set(df.order_id).difference(set(dfs4.order_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0746ccb1-4271-48a5-8f47-ae77168a6bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il n'y avait pas de colonne 'level_0' indésirable à supprimer.\n",
      "Une colonne 'index' indésirable a été supprimée.\n",
      "(103886, 5)\n"
     ]
    }
   ],
   "source": [
    "df = df[df.order_id != new_elt[0]]\n",
    "df = my.resindx(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcc0f8d-2ae3-430d-aada-0893b9b30ba9",
   "metadata": {},
   "source": [
    ">>-\n",
    "## 43. Merge_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30c82b21-64f5-420e-8c41-f4253266aa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(dfs5[[\"order_id\",\"review_score\"]], on=\"order_id\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d22000-a3a8-4c2e-a41d-5a78bd6f784b",
   "metadata": {},
   "source": [
    ">>-\n",
    "## 44. Cleaning_2 (et re-cleaning_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f81bfc54-4724-44a5-aadf-8c83db89a792",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_elts = list(set(df.order_id).difference(set(dfs5.order_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1770aee-faaf-45ae-b89a-a90ba11f6055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il n'y avait pas de colonne 'level_0' indésirable à supprimer.\n",
      "Une colonne 'index' indésirable a été supprimée.\n",
      "(104477, 6)\n"
     ]
    }
   ],
   "source": [
    "df = df[df.order_id != new_elt[0]]\n",
    "df = my.resindx(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d7d5c00-5eae-4abd-a0c3-a59105261ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il n'y avait pas de colonne 'level_0' indésirable à supprimer.\n",
      "Une colonne 'index' indésirable a été supprimée.\n",
      "(103677, 6)\n"
     ]
    }
   ],
   "source": [
    "df = df[df.review_score.isna() == False]\n",
    "df = my.resindx(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2088e5a-dba6-4675-b8f0-7ee86f0933ef",
   "metadata": {},
   "source": [
    ">>-\n",
    "## 45. Feature cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81ed6426-c062-4d4f-9978-45eb6d95643e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keeps = [\"customer_unique_id\",\"order_purchase_timestamp\",\"payment_value\",\"review_score\"]\n",
    "df = df[keeps]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94a01d5-1893-43cf-87d9-264353ae722b",
   "metadata": {
    "tags": []
   },
   "source": [
    ">>-\n",
    "## 46. Réorganisation RFM + rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe1a8f18-d393-453e-bd6f-be43c6df0179",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t0 = datetime.datetime.strptime(df.order_purchase_timestamp.max(), \"%Y-%m-%d %H:%M:%S\")\n",
    "df[\"recency_2\"] = pd.to_numeric(pd.to_datetime(df.order_purchase_timestamp))\n",
    "df[\"recency_2\"] = (df.recency_2.max() - df.recency_2)*10**-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15279f65-ca7e-412e-a891-c797b598f5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>customer_unique_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0000366f3b9a7992bf8c76cfdf3221e2</th>\n",
       "      <td>13847631.0</td>\n",
       "      <td>1</td>\n",
       "      <td>141.90</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000b849f77a49e4a4ce2b2a4ca5be3f</th>\n",
       "      <td>14105931.0</td>\n",
       "      <td>1</td>\n",
       "      <td>27.19</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           R  F       M    S\n",
       "customer_unique_id                                          \n",
       "0000366f3b9a7992bf8c76cfdf3221e2  13847631.0  1  141.90  5.0\n",
       "0000b849f77a49e4a4ce2b2a4ca5be3f  14105931.0  1   27.19  4.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = pd.DataFrame()\n",
    "dfs[\"R\"] = df.groupby(\"customer_unique_id\").recency_2.min()\n",
    "dfs[\"F\"] = df.groupby([\"customer_unique_id\",\"order_purchase_timestamp\"]).agg(\"count\").groupby(\"customer_unique_id\").count().payment_value\n",
    "dfs[\"M\"] = df.groupby(\"customer_unique_id\").payment_value.sum()\n",
    "dfs[\"S\"] = df.groupby(\"customer_unique_id\").review_score.min()\n",
    "dfs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54e5a47e-df24-4fb3-8795-7983f14a9d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95379 ,  92680\n",
      "Il y a 2.8% de clients ayant effectué plus d'un achat dans le dataset avant subsampling.\n"
     ]
    }
   ],
   "source": [
    "print(dfs.shape[0], \", \", sum(dfs.F == 1))\n",
    "pct = (1-sum(dfs.F == 1)/dfs.shape[0])*100\n",
    "pct = (sum(dfs.F > 1)/dfs.shape[0])*100 # idem car par construction F < 1 n'existe pas.\n",
    "print(\"Il y a {a:.1f}% de clients ayant effectué plus d'un achat dans le dataset avant subsampling.\".format(a=pct))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e864492-8db4-481f-837a-4861b9bcbafb",
   "metadata": {
    "tags": []
   },
   "source": [
    ">>-\n",
    "## 47. Fabrication des dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d63528f-02ab-4494-a66f-54a6869da3ea",
   "metadata": {
    "tags": []
   },
   "source": [
    ">>>-\n",
    "### 471. Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "849496a6-c8cf-4b04-a55e-d8f51d72317b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-17 17:30:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-10-01 00:00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-17 17:30:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-04 21:15:19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dates\n",
       "0  2018-10-17 17:30:18\n",
       "1  2018-10-01 00:00:01\n",
       "2  2018-09-17 17:30:18\n",
       "3  2016-09-04 21:15:19"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcies = pd.DataFrame([df.order_purchase_timestamp.max(),\n",
    "                     \"2018-10-01 00:00:01\",\n",
    "                     \"2018-09-17 17:30:18\",\n",
    "                     df.order_purchase_timestamp.min()],\n",
    "                    columns=[\"dates\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afd55ca1-2265-4874-894d-e3768e828227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dates</th>\n",
       "      <th>recencies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-17 17:30:18</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-10-01 00:00:01</td>\n",
       "      <td>1445417.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-09-17 17:30:18</td>\n",
       "      <td>2592000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-04 21:15:19</td>\n",
       "      <td>66773699.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 dates   recencies\n",
       "0  2018-10-17 17:30:18         0.0\n",
       "1  2018-10-01 00:00:01   1445417.0\n",
       "2  2018-09-17 17:30:18   2592000.0\n",
       "3  2016-09-04 21:15:19  66773699.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcies[\"recencies\"] = pd.to_numeric(pd.to_datetime(rcies.dates))\n",
    "rcies[\"recencies\"] = (rcies.recencies.max() - rcies.recencies)*10**-9\n",
    "rcies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0c3b4cf-665c-4474-b5a6-bef1bbf6fe63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "df_list.append(dfs[dfs.R <    rcies.recencies[1]])\n",
    "df_list.append(dfs[dfs.R <    rcies.recencies[2]])\n",
    "df_list.append(dfs[dfs.R <  2*rcies.recencies[2]])\n",
    "df_list.append(dfs[dfs.R < 12*rcies.recencies[2]]) # Ceux-ci vont me servir\n",
    "df_list.append(dfs[dfs.R < 13*rcies.recencies[2]]) # Ceux-ci vont me servir\n",
    "df_list.append(dfs[dfs.R < 14*rcies.recencies[2]]) # Ceux-ci vont me servir\n",
    "df_list.append(dfs[dfs.R < 15*rcies.recencies[2]]) # Ceux-ci vont me servir\n",
    "df_list.append(dfs[dfs.R < 16*rcies.recencies[2]]) # Ceux-ci vont me servir\n",
    "df_list.append(dfs[dfs.R > rcies.recencies[3] - 12*rcies.recencies[2]])\n",
    "df_list.append(dfs[dfs.R > rcies.recencies[3] -  2*rcies.recencies[2]])\n",
    "df_list.append(dfs[dfs.R > rcies.recencies[3] -    rcies.recencies[2]])\n",
    "#for i in range(len(df_list)):\n",
    "#    sns.scatterplot(df_list[i].R, df_list[i].F, df_list[i].M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81f222f0-8f65-4d2d-b3ed-0e8817071536",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_classif(df=df, cols_num=[\"R\",\"F\",\"M\",\"S\"], ns=0):\n",
    "    X = df[cols_num]\n",
    "\n",
    "    if ns:\n",
    "#        print(X.shape, sum(X.F == 1))\n",
    "        pct = (1-sum(X.F == 1)/X.shape[0])*100\n",
    "        print(\"Il y a {a:.1f}% de clients ayant effectué plus d'un achat \"\n",
    "              \"dans le dataset avant subsampling.\".format(a=pct))\n",
    "        X = X.sample(n=ns, weights=None, random_state=1)\n",
    "                     #frac=.1, weights=\"F\", random_state=1)\n",
    "#        print(X.shape, sum(X.F == 1))\n",
    "        pct = (1-sum(X.F == 1)/X.shape[0])*100\n",
    "        print(\"Il y a {a:.1f}% de clients ayant effectué plus d'un achat \"\n",
    "              \"dans la subsample sélectionnée.\".format(a=pct))\n",
    "\n",
    "    X[cols_num] = scaler.fit_transform(X[cols_num])\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325ee994-747a-4de6-86b6-46906fe84126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d58945b-ede3-4682-946a-4aac32f989c1",
   "metadata": {
    "tags": []
   },
   "source": [
    ">>>-\n",
    "### 472. dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1b0ca98-08e8-4319-bfab-61e650a3ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for i in range(3,8):\n",
    "    scaler = StandardScaler()\n",
    "    X = init_classif(df = df_list[i])\n",
    "    model = KMeans(n_clusters=4, init=\"k-means++\")\n",
    "    model = model.fit(X)\n",
    "    y_pred.append(model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8318579c-5899-436e-b2a8-dba8214e1608",
   "metadata": {},
   "source": [
    "- fit d'un premier kmeans 0 avec 1000 clients et garder son scaler\n",
    "- predict avec le même kmeans 0 avec les 1100 clients du mois suivant (ou semaine)\n",
    "et fit, predict d'un nouveau kmeans i+1 avec son scaler\n",
    "- comparer les labels de chaque kmeans i+1 à {ceux du kmeans 0 appliqué au dataset de taille i+1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "53554954-773f-4985-ace1-999e1bf67845",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [66323, 70495]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#adjusted_rand_score(labels_true, labels_pred)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#ARI_voisins = [adjusted_rand_score(y_pred[i], y_pred[i+1]) for i in range(len(y_pred)-1)]\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m ARI_1 \u001b[38;5;241m=\u001b[39m [adjusted_rand_score(y_pred[\u001b[38;5;241m0\u001b[39m], y_pred[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_pred)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m      4\u001b[0m plot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m), ARI_1)\n",
      "Input \u001b[1;32mIn [39]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#adjusted_rand_score(labels_true, labels_pred)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#ARI_voisins = [adjusted_rand_score(y_pred[i], y_pred[i+1]) for i in range(len(y_pred)-1)]\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m ARI_1 \u001b[38;5;241m=\u001b[39m [\u001b[43madjusted_rand_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y_pred)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m      4\u001b[0m plot(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m5\u001b[39m), ARI_1)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\cluster\\_supervised.py:391\u001b[0m, in \u001b[0;36madjusted_rand_score\u001b[1;34m(labels_true, labels_pred)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madjusted_rand_score\u001b[39m(labels_true, labels_pred):\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;124;03m\"\"\"Rand index adjusted for chance.\u001b[39;00m\n\u001b[0;32m    312\u001b[0m \n\u001b[0;32m    313\u001b[0m \u001b[38;5;124;03m    The Rand Index computes a similarity measure between two clusterings\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;124;03m    adjusted_mutual_info_score : Adjusted Mutual Information.\u001b[39;00m\n\u001b[0;32m    390\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 391\u001b[0m     (tn, fp), (fn, tp) \u001b[38;5;241m=\u001b[39m \u001b[43mpair_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;66;03m# convert to Python integer types, to avoid overflow or underflow\u001b[39;00m\n\u001b[0;32m    393\u001b[0m     tn, fp, fn, tp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(tn), \u001b[38;5;28mint\u001b[39m(fp), \u001b[38;5;28mint\u001b[39m(fn), \u001b[38;5;28mint\u001b[39m(tp)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\cluster\\_supervised.py:222\u001b[0m, in \u001b[0;36mpair_confusion_matrix\u001b[1;34m(labels_true, labels_pred)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpair_confusion_matrix\u001b[39m(labels_true, labels_pred):\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;124;03m\"\"\"Pair confusion matrix arising from two clusterings.\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \n\u001b[0;32m    165\u001b[0m \u001b[38;5;124;03m    The pair confusion matrix :math:`C` computes a 2 by 2 similarity matrix\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;124;03m      https://link.springer.com/article/10.1007%2FBF01908075\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 222\u001b[0m     labels_true, labels_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_clusterings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    223\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mint64(labels_true\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;66;03m# Computation using the contingency data\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\cluster\\_supervised.py:72\u001b[0m, in \u001b[0;36mcheck_clusterings\u001b[1;34m(labels_true, labels_pred)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels_pred\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     71\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels_pred must be 1D: shape is \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (labels_pred\u001b[38;5;241m.\u001b[39mshape,))\n\u001b[1;32m---> 72\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels_true, labels_pred\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:332\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    330\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[0;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    333\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    334\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[0;32m    335\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [66323, 70495]"
     ]
    }
   ],
   "source": [
    "#adjusted_rand_score(labels_true, labels_pred)\n",
    "#ARI_voisins = [adjusted_rand_score(y_pred[i], y_pred[i+1]) for i in range(len(y_pred)-1)]\n",
    "ARI_1 = [adjusted_rand_score(y_pred[0], y_pred[i+1]) for i in range(len(y_pred)-1)]\n",
    "plot(range(5), ARI_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d28d07-687a-4049-ac5f-d1f007b16333",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "tags": [
   "hide-cell"
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
